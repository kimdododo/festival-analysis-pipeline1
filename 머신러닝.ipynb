{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b60f48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 폰트 적용: Malgun Gothic\n",
      "[INFO] 학습 데이터: X=(64367, 28), y=(64367,), features=28\n",
      "[OOF] RMSE=0.0605  R²=0.9979\n",
      "\n",
      "[Permutation Importance - Top 20]\n",
      "         feature  importance      std\n",
      "         내수위_rm3    2.474746 0.013235\n",
      "        내수위_lag2    0.185599 0.000524\n",
      "        내수위_lag1    0.067800 0.000339\n",
      "       내수위_diff1    0.009666 0.000071\n",
      "        유역면적(ha)    0.001857 0.000026\n",
      "             외수위    0.001679 0.000071\n",
      "         내수위_rm6    0.001145 0.000009\n",
      "     hydro_value    0.001119 0.000019\n",
      "     rain_mm_rm3    0.000980 0.000007\n",
      "         rain_mm    0.000946 0.000008\n",
      "       외수위_diff1    0.000287 0.000005\n",
      "         외수위_rm3    0.000196 0.000007\n",
      " hydro_value_rm3    0.000178 0.000004\n",
      "     rain_mm_rm6    0.000105 0.000005\n",
      " hydro_value_rm6    0.000102 0.000004\n",
      "hydro_value_lag1    0.000097 0.000002\n",
      "         외수위_rm6    0.000085 0.000002\n",
      "        외수위_lag2    0.000084 0.000004\n",
      "        외수위_lag1    0.000084 0.000006\n",
      "hydro_value_lag2    0.000080 0.000001\n",
      "\n",
      "[INFO] SHAP 해석은 건너뜁니다 → 사유: ExplainerError('Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was 3.341669, while the model output was 3.497799. If this difference is acceptable you can set check_additivity=False to disable this check.')\n",
      "      필요 시: pip install shap  후 재실행하세요.\n",
      "\n",
      "[DONE] 모든 작업 완료. 플롯은 figs/ 폴더를 확인하세요.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =========================================================\n",
    "# 강서구 펌프장 내수위 예측 - 머신러닝 베이스라인 (한글패치 포함, 원클릭 실행)\n",
    "# - Files:\n",
    "#   /mnt/data/1.csv\n",
    "#   /mnt/data/hydro_raw_2017_2025.csv\n",
    "#   /mnt/data/rain_2017_2024_merged.csv\n",
    "#   /mnt/data/sewer_2017_2024_merged.csv\n",
    "# - Output:\n",
    "#   figs/perm_importance.png\n",
    "#   figs/model_importance.png (지원 시)\n",
    "#   figs/shap_summary_dot.png, figs/shap_summary_bar.png (설치 시)\n",
    "# =========================================================\n",
    "import os, re, platform, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------\n",
    "# 0) 한글 폰트 자동 패치\n",
    "# ------------------------------\n",
    "def patch_korean_font():\n",
    "    sysname = platform.system().lower()\n",
    "    font_candidates = []\n",
    "    if \"windows\" in sysname:\n",
    "        font_candidates = [\"Malgun Gothic\", \"맑은 고딕\"]\n",
    "    elif \"darwin\" in sysname:  # macOS\n",
    "        font_candidates = [\"AppleGothic\"]\n",
    "    else:\n",
    "        font_candidates = [\"NanumGothic\", \"NanumBarunGothic\", \"DejaVu Sans\"]\n",
    "    for f in font_candidates:\n",
    "        try:\n",
    "            matplotlib.rcParams[\"font.family\"] = f\n",
    "            # 테스트 렌더 (폰트 미설치면 오류 발생 가능)\n",
    "            _ = plt.figure(); plt.plot([0,1],[0,1]); plt.title(\"폰트테스트: 한글 OK?\"); plt.close()\n",
    "            print(f\"[INFO] 폰트 적용: {f}\")\n",
    "            break\n",
    "        except Exception:\n",
    "            continue\n",
    "    # 마이너스 깨짐 방지\n",
    "    matplotlib.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "os.makedirs(\"figs\", exist_ok=True)\n",
    "patch_korean_font()\n",
    "\n",
    "# ------------------------------\n",
    "# 1) 파일 경로 & 파라미터\n",
    "# ------------------------------\n",
    "PUMP_FILE   = \"1.csv\"\n",
    "HYDRO_FILE  = \"hydro_raw_2017_2025.csv\"\n",
    "RAIN_FILE   = \"rain_2017_2024_merged.csv\"\n",
    "SEWER_FILE  = \"sewer_2017_2024_merged.csv\"\n",
    "\n",
    "TARGET = \"내수위\"            # ← '외수위'로 교체 가능\n",
    "USE_SEWER = True             # 하수관로도 asof로 결합\n",
    "RAIN_TOL   = \"1H\"            # 강우 asof 허용\n",
    "HYDRO_TOL  = \"1H\"            # 수문 asof 허용\n",
    "SEWER_TOL  = \"30min\"         # 하수관로 asof 허용\n",
    "\n",
    "# ------------------------------\n",
    "# 2) 데이터 로드\n",
    "# ------------------------------\n",
    "pump = pd.read_csv(PUMP_FILE)\n",
    "# timestamp 확보\n",
    "if \"timestamp\" in pump.columns:\n",
    "    pump[\"timestamp\"] = pd.to_datetime(pump[\"timestamp\"], errors=\"coerce\")\n",
    "elif {\"일자\",\"시각\"} <= set(pump.columns):\n",
    "    # 보수적 병합: 일자/시각 중 하나라도 파싱되면 사용\n",
    "    ts_a = pd.to_datetime(pump[\"일자\"], errors=\"coerce\")\n",
    "    ts_b = pd.to_datetime(pump[\"시각\"], errors=\"coerce\")\n",
    "    pump[\"timestamp\"] = ts_a.combine_first(ts_b)\n",
    "else:\n",
    "    raise KeyError(\"펌프 데이터에 'timestamp' 또는 ['일자','시각']가 필요합니다.\")\n",
    "\n",
    "pump = pump.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "# 강우\n",
    "rain = pd.read_csv(RAIN_FILE)\n",
    "if \"timestamp\" not in rain.columns:\n",
    "    if \"일시\" in rain.columns:\n",
    "        rain[\"timestamp\"] = pd.to_datetime(rain[\"일시\"], errors=\"coerce\")\n",
    "    else:\n",
    "        raise KeyError(\"강우 데이터에 'timestamp' 또는 '일시'가 필요합니다.\")\n",
    "rain[\"timestamp\"] = pd.to_datetime(rain[\"timestamp\"], errors=\"coerce\")\n",
    "if \"강수량(mm)\" not in rain.columns:\n",
    "    raise KeyError(\"강우 데이터에 '강수량(mm)' 컬럼이 필요합니다.\")\n",
    "rain = rain[[\"timestamp\",\"강수량(mm)\"]].dropna(subset=[\"timestamp\"]).sort_values(\"timestamp\")\n",
    "rain.rename(columns={\"강수량(mm)\":\"rain_mm\"}, inplace=True)\n",
    "rain[\"rain_mm\"] = pd.to_numeric(rain[\"rain_mm\"], errors=\"coerce\")\n",
    "\n",
    "# 수문 (wide→long)\n",
    "hydro = pd.read_csv(HYDRO_FILE)\n",
    "if \"관측 일시\" not in hydro.columns:\n",
    "    raise KeyError(\"수문 데이터에 '관측 일시' 컬럼이 필요합니다.\")\n",
    "date_col = \"관측 일시\"\n",
    "hour_cols = [c for c in hydro.columns if re.fullmatch(r\"\\s*\\d{1,2}시\\s*\", str(c))]\n",
    "if not hour_cols:\n",
    "    raise KeyError(\"수문 데이터에서 시간 컬럼(예: '01시'~'24시')을 찾지 못했습니다.\")\n",
    "id_vars = [date_col]\n",
    "for c in [\"station\", \"year\"]:\n",
    "    if c in hydro.columns:\n",
    "        id_vars.append(c)\n",
    "hydro_long = hydro.melt(id_vars=id_vars, value_vars=hour_cols,\n",
    "                        var_name=\"hour_k\", value_name=\"hydro_value\")\n",
    "hydro_long[date_col] = pd.to_datetime(hydro_long[date_col], errors=\"coerce\").dt.floor(\"D\")\n",
    "hydro_long[\"hour_num\"] = hydro_long[\"hour_k\"].astype(str).str.extract(r\"(\\d{1,2})\").astype(float)\n",
    "hydro_long[\"hour_mod\"] = (hydro_long[\"hour_num\"] % 24).astype(\"Int64\")\n",
    "hydro_long[\"timestamp\"] = hydro_long[date_col] + pd.to_timedelta(hydro_long[\"hour_mod\"].astype(float), unit=\"h\")\n",
    "hydro_long[\"hydro_value\"] = pd.to_numeric(hydro_long[\"hydro_value\"], errors=\"coerce\")\n",
    "hydro_agg = (hydro_long.dropna(subset=[\"timestamp\"])\n",
    "                      .groupby(\"timestamp\", as_index=False)[\"hydro_value\"]\n",
    "                      .mean().sort_values(\"timestamp\"))\n",
    "\n",
    "# 하수관로(옵션)\n",
    "sewer_agg = None\n",
    "if USE_SEWER:\n",
    "    sewer = pd.read_csv(SEWER_FILE)\n",
    "    if {\"timestamp\",\"water_level\"} <= set(sewer.columns):\n",
    "        sewer[\"timestamp\"] = pd.to_datetime(sewer[\"timestamp\"], errors=\"coerce\")\n",
    "        sewer = sewer.sort_values(\"timestamp\")\n",
    "        sewer_agg = sewer.groupby(\"timestamp\", as_index=False)[\"water_level\"].mean()\n",
    "    else:\n",
    "        print(\"[WARN] sewer 스키마가 예상과 다릅니다. sewer 결합을 건너뜁니다.\")\n",
    "        USE_SEWER = False\n",
    "\n",
    "# ------------------------------\n",
    "# 3) 안전한 asof merge 유틸\n",
    "# ------------------------------\n",
    "def merge_asof_(left, right, on_left=\"timestamp\", on_right=\"timestamp\",\n",
    "                tol=\"1H\", direction=\"backward\"):\n",
    "    if right is None or len(right)==0:\n",
    "        return left\n",
    "    L = left.sort_values(on_left).copy()\n",
    "    R = right.sort_values(on_right).copy()\n",
    "    L = pd.merge_asof(L, R, left_on=on_left, right_on=on_right,\n",
    "                      direction=direction, tolerance=pd.Timedelta(tol))\n",
    "    if on_right in L.columns and on_right != on_left:\n",
    "        L = L.drop(columns=[on_right])\n",
    "    return L\n",
    "\n",
    "# ------------------------------\n",
    "# 4) 시계열 병합\n",
    "# ------------------------------\n",
    "df = pump.copy().sort_values(\"timestamp\")\n",
    "df = merge_asof_(df, rain.rename(columns={\"timestamp\":\"ts_rain\"}),\n",
    "                 on_left=\"timestamp\", on_right=\"ts_rain\", tol=RAIN_TOL)\n",
    "df = merge_asof_(df, hydro_agg, tol=HYDRO_TOL)\n",
    "if USE_SEWER:\n",
    "    df = merge_asof_(df, sewer_agg.rename(columns={\"timestamp\":\"ts_sewer\"}),\n",
    "                     on_left=\"timestamp\", on_right=\"ts_sewer\", tol=SEWER_TOL)\n",
    "\n",
    "# ------------------------------\n",
    "# 5) 결측 보정(간단하고 튼튼하게)\n",
    "# ------------------------------\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "df[num_cols] = df[num_cols].ffill().bfill()\n",
    "for c in num_cols:\n",
    "    df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "# ------------------------------\n",
    "# 6) 그룹별 시계열 파생 (펌프장명 단위; 누설 방지)\n",
    "# ------------------------------\n",
    "def add_time_features(df, group_col=\"펌프장명\",\n",
    "                      base_cols=(\"rain_mm\",\"hydro_value\",\"water_level\",\"내수위\",\"외수위\")):\n",
    "    df = df.copy()\n",
    "    if group_col in df.columns:\n",
    "        df = df.sort_values([group_col, \"timestamp\"])\n",
    "        g = df.groupby(group_col, group_keys=False)\n",
    "        for col in base_cols:\n",
    "            if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):\n",
    "                df[f\"{col}_lag1\"]  = g[col].shift(1)\n",
    "                df[f\"{col}_lag2\"]  = g[col].shift(2)\n",
    "                df[f\"{col}_diff1\"] = g[col].diff()\n",
    "                rm3 = g[col].rolling(3).mean().reset_index(level=0, drop=True)\n",
    "                rm6 = g[col].rolling(6).mean().reset_index(level=0, drop=True)\n",
    "                df[f\"{col}_rm3\"] = rm3\n",
    "                df[f\"{col}_rm6\"] = rm6\n",
    "    else:\n",
    "        df = df.sort_values(\"timestamp\")\n",
    "        for col in base_cols:\n",
    "            if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):\n",
    "                df[f\"{col}_lag1\"]  = df[col].shift(1)\n",
    "                df[f\"{col}_lag2\"]  = df[col].shift(2)\n",
    "                df[f\"{col}_diff1\"] = df[col].diff()\n",
    "                df[f\"{col}_rm3\"]   = df[col].rolling(3).mean()\n",
    "                df[f\"{col}_rm6\"]   = df[col].rolling(6).mean()\n",
    "    return df\n",
    "\n",
    "df = add_time_features(df)\n",
    "\n",
    "# 파생으로 생긴 NaN 보정\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for c in num_cols:\n",
    "    df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "# ------------------------------\n",
    "# 7) 학습 데이터 구성\n",
    "# ------------------------------\n",
    "drop_cols = [\"timestamp\",\"일자\",\"시각\",\"펌프장 주소\",\"위도\",\"경도\",\"데이터기준일자\", TARGET]\n",
    "feature_cols = [c for c in df.columns if c not in drop_cols and df[c].dtype != \"O\"]\n",
    "X = df[feature_cols].copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "mask = X.notna().all(axis=1) & y.notna()\n",
    "X = X[mask]; y = y[mask]\n",
    "print(f\"[INFO] 학습 데이터: X={X.shape}, y={y.shape}, features={len(feature_cols)}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 8) 모델 학습/검증 (HGB, 5Fold OOF)\n",
    "# ------------------------------\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_pred, oof_true = [], []\n",
    "\n",
    "for tr_idx, va_idx in kf.split(X):\n",
    "    est = HistGradientBoostingRegressor(\n",
    "        max_depth=6, learning_rate=0.08, max_iter=500,\n",
    "        l2_regularization=0.0, random_state=42\n",
    "    )\n",
    "    est.fit(X.iloc[tr_idx], y.iloc[tr_idx])\n",
    "    pred = est.predict(X.iloc[va_idx])\n",
    "    oof_pred.append(pred); oof_true.append(y.iloc[va_idx].values)\n",
    "\n",
    "oof_pred = np.concatenate(oof_pred)\n",
    "oof_true = np.concatenate(oof_true)\n",
    "\n",
    "# sklearn 구버전 호환: RMSE = sqrt(MSE)\n",
    "mse = mean_squared_error(oof_true, oof_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2   = r2_score(oof_true, oof_pred)\n",
    "print(f\"[OOF] RMSE={rmse:.4f}  R²={r2:.4f}\")\n",
    "\n",
    "# 전체 적합 모델(해석용)\n",
    "est_final = HistGradientBoostingRegressor(\n",
    "    max_depth=6, learning_rate=0.08, max_iter=500,\n",
    "    l2_regularization=0.0, random_state=42\n",
    ").fit(X, y)\n",
    "\n",
    "# ------------------------------\n",
    "# 9) 중요도: Permutation / Model-based\n",
    "# ------------------------------\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "perm = permutation_importance(est_final, X, y, n_repeats=8, random_state=42, n_jobs=-1)\n",
    "imp_perm = (pd.DataFrame({\"feature\": feature_cols,\n",
    "                          \"importance\": perm.importances_mean,\n",
    "                          \"std\": perm.importances_std})\n",
    "            .sort_values(\"importance\", ascending=False).reset_index(drop=True))\n",
    "print(\"\\n[Permutation Importance - Top 20]\")\n",
    "print(imp_perm.head(20).to_string(index=False))\n",
    "\n",
    "# Plot 저장\n",
    "topk = 20\n",
    "imp_plot = imp_perm.head(topk).iloc[::-1]\n",
    "plt.figure(figsize=(9, max(4, topk*0.4)))\n",
    "plt.barh(imp_plot[\"feature\"], imp_plot[\"importance\"])\n",
    "plt.xlabel(\"Permutation Importance (mean decrease)\")\n",
    "plt.ylabel(\"Feature\"); plt.title(\"Top-20 Permutation Importance (HGB)\")\n",
    "plt.tight_layout(); plt.savefig(\"figs/perm_importance.png\", dpi=200); plt.close()\n",
    "\n",
    "# Model-based (HGB 지원 시)\n",
    "if hasattr(est_final, \"feature_importances_\"):\n",
    "    imp_model = (pd.DataFrame({\"feature\": feature_cols,\n",
    "                               \"importance\": est_final.feature_importances_})\n",
    "                 .sort_values(\"importance\", ascending=False))\n",
    "    print(\"\\n[Model-based Importance - Top 20]\")\n",
    "    print(imp_model.head(20).to_string(index=False))\n",
    "\n",
    "    imp_plot2 = imp_model.head(topk).iloc[::-1]\n",
    "    plt.figure(figsize=(9, max(4, topk*0.4)))\n",
    "    plt.barh(imp_plot2[\"feature\"], imp_plot2[\"importance\"])\n",
    "    plt.xlabel(\"Model-based Importance\"); plt.ylabel(\"Feature\")\n",
    "    plt.title(\"Top-20 Model-based Importance (HGB)\")\n",
    "    plt.tight_layout(); plt.savefig(\"figs/model_importance.png\", dpi=200); plt.close()\n",
    "\n",
    "# ------------------------------\n",
    "# 10) (옵션) SHAP 요약 플롯\n",
    "# ------------------------------\n",
    "try:\n",
    "    import shap\n",
    "    # 일부 버전 경고 회피 플래그(필요 시)\n",
    "    try:\n",
    "        shap.utils._legacy = True\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    nsample = min(2000, len(X))\n",
    "    rng = np.random.default_rng(42)\n",
    "    idx = rng.choice(len(X), size=nsample, replace=False)\n",
    "    Xs = X.iloc[idx].copy()\n",
    "\n",
    "    explainer = shap.Explainer(est_final, Xs)\n",
    "    sh = explainer(Xs)\n",
    "\n",
    "    # summary dot\n",
    "    plt.figure()\n",
    "    shap.summary_plot(sh, Xs, plot_type=\"dot\", show=False, max_display=20)\n",
    "    plt.title(\"SHAP Summary (dot)\")\n",
    "    plt.tight_layout(); plt.savefig(\"figs/shap_summary_dot.png\", dpi=200); plt.close()\n",
    "\n",
    "    # summary bar\n",
    "    plt.figure()\n",
    "    shap.summary_plot(sh, Xs, plot_type=\"bar\", show=False, max_display=20)\n",
    "    plt.title(\"SHAP Summary (bar)\")\n",
    "    plt.tight_layout(); plt.savefig(\"figs/shap_summary_bar.png\", dpi=200); plt.close()\n",
    "\n",
    "    print(\"\\n[INFO] SHAP 요약 플롯 저장 완료: figs/shap_summary_*.png\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\n[INFO] SHAP 해석은 건너뜁니다 → 사유:\", repr(e))\n",
    "    print(\"      필요 시: pip install shap  후 재실행하세요.\")\n",
    "\n",
    "print(\"\\n[DONE] 모든 작업 완료. 플롯은 figs/ 폴더를 확인하세요.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ee5d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 폰트 적용: Malgun Gothic\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5061\n",
      "[LightGBM] [Info] Number of data points in the train set: 51493, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 2.373905\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5063\n",
      "[LightGBM] [Info] Number of data points in the train set: 51493, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 2.374053\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5064\n",
      "[LightGBM] [Info] Number of data points in the train set: 51494, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 2.377947\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5064\n",
      "[LightGBM] [Info] Number of data points in the train set: 51494, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 2.373446\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5069\n",
      "[LightGBM] [Info] Number of data points in the train set: 51494, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 2.372120\n",
      "\n",
      "[리더보드]\n",
      "  model      RMSE        R2\n",
      "0   CAT  0.028896  0.999521\n",
      "1  LGBM  0.037166  0.999207\n",
      "2   GBR  0.041377  0.999017\n",
      "3   XGB  0.053019  0.998387\n",
      "4   HGB  0.060547  0.997896\n",
      "\n",
      "[INFO] 상위 2개 모델 앙상블: ['CAT', 'LGBM']\n",
      "[앙상블] RMSE=0.0283, R²=0.9995\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# =========================================================\n",
    "# 강서구 펌프장 내수위 예측 - 머신러닝 베이스라인 (한글패치 포함, 원클릭 실행)\n",
    "# - Files:\n",
    "#   /mnt/data/1.csv\n",
    "#   /mnt/data/hydro_raw_2017_2025.csv\n",
    "#   /mnt/data/rain_2017_2024_merged.csv\n",
    "#   /mnt/data/sewer_2017_2024_merged.csv\n",
    "# - Output:\n",
    "#   figs/perm_importance.png\n",
    "#   figs/model_importance.png (지원 시)\n",
    "#   figs/shap_summary_dot.png, figs/shap_summary_bar.png (설치 시)\n",
    "# =========================================================\n",
    "import os, re, platform, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------\n",
    "# 0) 한글 폰트 자동 패치\n",
    "# ------------------------------\n",
    "def patch_korean_font():\n",
    "    sysname = platform.system().lower()\n",
    "    font_candidates = []\n",
    "    if \"windows\" in sysname:\n",
    "        font_candidates = [\"Malgun Gothic\", \"맑은 고딕\"]\n",
    "    elif \"darwin\" in sysname:  # macOS\n",
    "        font_candidates = [\"AppleGothic\"]\n",
    "    else:\n",
    "        font_candidates = [\"NanumGothic\", \"NanumBarunGothic\", \"DejaVu Sans\"]\n",
    "    for f in font_candidates:\n",
    "        try:\n",
    "            matplotlib.rcParams[\"font.family\"] = f\n",
    "            # 테스트 렌더 (폰트 미설치면 오류 발생 가능)\n",
    "            _ = plt.figure(); plt.plot([0,1],[0,1]); plt.title(\"폰트테스트: 한글 OK?\"); plt.close()\n",
    "            print(f\"[INFO] 폰트 적용: {f}\")\n",
    "            break\n",
    "        except Exception:\n",
    "            continue\n",
    "    # 마이너스 깨짐 방지\n",
    "    matplotlib.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "os.makedirs(\"figs\", exist_ok=True)\n",
    "patch_korean_font()\n",
    "\n",
    "# ------------------------------\n",
    "# 1) 파일 경로 & 파라미터\n",
    "# ------------------------------\n",
    "PUMP_FILE   = \"1.csv\"\n",
    "HYDRO_FILE  = \"hydro_raw_2017_2025.csv\"\n",
    "RAIN_FILE   = \"rain_2017_2024_merged.csv\"\n",
    "SEWER_FILE  = \"sewer_2017_2024_merged.csv\"\n",
    "\n",
    "TARGET = \"내수위\"            # ← '외수위'로 교체 가능\n",
    "USE_SEWER = True             # 하수관로도 asof로 결합\n",
    "RAIN_TOL   = \"1H\"            # 강우 asof 허용\n",
    "HYDRO_TOL  = \"1H\"            # 수문 asof 허용\n",
    "SEWER_TOL  = \"30min\"         # 하수관로 asof 허용\n",
    "\n",
    "# ------------------------------\n",
    "# 2) 데이터 로드\n",
    "# ------------------------------\n",
    "pump = pd.read_csv(PUMP_FILE)\n",
    "# timestamp 확보\n",
    "if \"timestamp\" in pump.columns:\n",
    "    pump[\"timestamp\"] = pd.to_datetime(pump[\"timestamp\"], errors=\"coerce\")\n",
    "elif {\"일자\",\"시각\"} <= set(pump.columns):\n",
    "    # 보수적 병합: 일자/시각 중 하나라도 파싱되면 사용\n",
    "    ts_a = pd.to_datetime(pump[\"일자\"], errors=\"coerce\")\n",
    "    ts_b = pd.to_datetime(pump[\"시각\"], errors=\"coerce\")\n",
    "    pump[\"timestamp\"] = ts_a.combine_first(ts_b)\n",
    "else:\n",
    "    raise KeyError(\"펌프 데이터에 'timestamp' 또는 ['일자','시각']가 필요합니다.\")\n",
    "\n",
    "pump = pump.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "# 강우\n",
    "rain = pd.read_csv(RAIN_FILE)\n",
    "if \"timestamp\" not in rain.columns:\n",
    "    if \"일시\" in rain.columns:\n",
    "        rain[\"timestamp\"] = pd.to_datetime(rain[\"일시\"], errors=\"coerce\")\n",
    "    else:\n",
    "        raise KeyError(\"강우 데이터에 'timestamp' 또는 '일시'가 필요합니다.\")\n",
    "rain[\"timestamp\"] = pd.to_datetime(rain[\"timestamp\"], errors=\"coerce\")\n",
    "if \"강수량(mm)\" not in rain.columns:\n",
    "    raise KeyError(\"강우 데이터에 '강수량(mm)' 컬럼이 필요합니다.\")\n",
    "rain = rain[[\"timestamp\",\"강수량(mm)\"]].dropna(subset=[\"timestamp\"]).sort_values(\"timestamp\")\n",
    "rain.rename(columns={\"강수량(mm)\":\"rain_mm\"}, inplace=True)\n",
    "rain[\"rain_mm\"] = pd.to_numeric(rain[\"rain_mm\"], errors=\"coerce\")\n",
    "\n",
    "# 수문 (wide→long)\n",
    "hydro = pd.read_csv(HYDRO_FILE)\n",
    "if \"관측 일시\" not in hydro.columns:\n",
    "    raise KeyError(\"수문 데이터에 '관측 일시' 컬럼이 필요합니다.\")\n",
    "date_col = \"관측 일시\"\n",
    "hour_cols = [c for c in hydro.columns if re.fullmatch(r\"\\s*\\d{1,2}시\\s*\", str(c))]\n",
    "if not hour_cols:\n",
    "    raise KeyError(\"수문 데이터에서 시간 컬럼(예: '01시'~'24시')을 찾지 못했습니다.\")\n",
    "id_vars = [date_col]\n",
    "for c in [\"station\", \"year\"]:\n",
    "    if c in hydro.columns:\n",
    "        id_vars.append(c)\n",
    "hydro_long = hydro.melt(id_vars=id_vars, value_vars=hour_cols,\n",
    "                        var_name=\"hour_k\", value_name=\"hydro_value\")\n",
    "hydro_long[date_col] = pd.to_datetime(hydro_long[date_col], errors=\"coerce\").dt.floor(\"D\")\n",
    "hydro_long[\"hour_num\"] = hydro_long[\"hour_k\"].astype(str).str.extract(r\"(\\d{1,2})\").astype(float)\n",
    "hydro_long[\"hour_mod\"] = (hydro_long[\"hour_num\"] % 24).astype(\"Int64\")\n",
    "hydro_long[\"timestamp\"] = hydro_long[date_col] + pd.to_timedelta(hydro_long[\"hour_mod\"].astype(float), unit=\"h\")\n",
    "hydro_long[\"hydro_value\"] = pd.to_numeric(hydro_long[\"hydro_value\"], errors=\"coerce\")\n",
    "hydro_agg = (hydro_long.dropna(subset=[\"timestamp\"])\n",
    "                      .groupby(\"timestamp\", as_index=False)[\"hydro_value\"]\n",
    "                      .mean().sort_values(\"timestamp\"))\n",
    "\n",
    "# 하수관로(옵션)\n",
    "sewer_agg = None\n",
    "if USE_SEWER:\n",
    "    sewer = pd.read_csv(SEWER_FILE)\n",
    "    if {\"timestamp\",\"water_level\"} <= set(sewer.columns):\n",
    "        sewer[\"timestamp\"] = pd.to_datetime(sewer[\"timestamp\"], errors=\"coerce\")\n",
    "        sewer = sewer.sort_values(\"timestamp\")\n",
    "        sewer_agg = sewer.groupby(\"timestamp\", as_index=False)[\"water_level\"].mean()\n",
    "    else:\n",
    "        print(\"[WARN] sewer 스키마가 예상과 다릅니다. sewer 결합을 건너뜁니다.\")\n",
    "        USE_SEWER = False\n",
    "\n",
    "# ------------------------------\n",
    "# 2) 후보 모델 정의\n",
    "# ------------------------------\n",
    "models = {}\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, GradientBoostingRegressor\n",
    "models[\"HGB\"] = HistGradientBoostingRegressor(max_depth=6, learning_rate=0.08, max_iter=500, random_state=42)\n",
    "models[\"GBR\"] = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    models[\"XGB\"] = XGBRegressor(\n",
    "        n_estimators=600, max_depth=6, learning_rate=0.05, subsample=0.8, colsample_bytree=0.8,\n",
    "        reg_lambda=1.0, random_state=42, n_jobs=-1, tree_method=\"hist\"\n",
    "    )\n",
    "except: pass\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    models[\"LGBM\"] = lgb.LGBMRegressor(\n",
    "        n_estimators=1200, learning_rate=0.05, subsample=0.8, colsample_bytree=0.8,\n",
    "        random_state=42, n_jobs=-1\n",
    "    )\n",
    "except: pass\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostRegressor\n",
    "    models[\"CAT\"] = CatBoostRegressor(\n",
    "        iterations=1200, depth=6, learning_rate=0.05,\n",
    "        loss_function=\"RMSE\", random_seed=42, verbose=False\n",
    "    )\n",
    "except: pass\n",
    "\n",
    "# ------------------------------\n",
    "# 3) KFold OOF + 개별 시각화\n",
    "# ------------------------------\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "leaderboard = []\n",
    "oof_preds_by_model = {}\n",
    "\n",
    "for name, est in models.items():\n",
    "    oof_pred, oof_true = [], []\n",
    "    for tr_idx, va_idx in kf.split(X):\n",
    "        Xt, Xv, yt, yv = X.iloc[tr_idx], X.iloc[va_idx], y.iloc[tr_idx], y.iloc[va_idx]\n",
    "        est_ = est.__class__(**getattr(est, \"get_params\", lambda: {})())\n",
    "        est_.fit(Xt, yt)\n",
    "        pv = est_.predict(Xv)\n",
    "        oof_pred.append(pv); oof_true.append(yv.values)\n",
    "    oof_pred, oof_true = np.concatenate(oof_pred), np.concatenate(oof_true)\n",
    "\n",
    "    mse = mean_squared_error(oof_true, oof_pred)\n",
    "    rmse, r2 = math.sqrt(mse), r2_score(oof_true, oof_pred)\n",
    "    leaderboard.append({\"model\": name, \"RMSE\": rmse, \"R2\": r2})\n",
    "    oof_preds_by_model[name] = (oof_true, oof_pred)\n",
    "\n",
    "    # 산점도 + 회귀선\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(oof_true, oof_pred, s=8, alpha=0.6)\n",
    "    lims_min, lims_max = min(oof_true.min(), oof_pred.min()), max(oof_true.max(), oof_pred.max())\n",
    "    plt.plot([lims_min, lims_max],[lims_min, lims_max])\n",
    "    X_mat = np.c_[np.ones_like(oof_true), oof_true]\n",
    "    beta, *_ = np.linalg.lstsq(X_mat, oof_pred, rcond=None)\n",
    "    line_x = np.linspace(lims_min, lims_max, 100)\n",
    "    plt.plot(line_x, beta[0]+beta[1]*line_x)\n",
    "    plt.xlabel(\"실측값\"); plt.ylabel(\"예측값\")\n",
    "    plt.title(f\"{name} 회귀선\\nRMSE={rmse:.3f}, R²={r2:.3f}\")\n",
    "    plt.tight_layout(); plt.savefig(f\"figs/scatter_regline_{name}.png\", dpi=200); plt.close()\n",
    "\n",
    "leader_df = pd.DataFrame(leaderboard).sort_values(\"RMSE\").reset_index(drop=True)\n",
    "print(\"\\n[리더보드]\")\n",
    "print(leader_df)\n",
    "\n",
    "# ------------------------------\n",
    "# 4) 상위 2개 모델 앙상블\n",
    "# ------------------------------\n",
    "if len(leader_df) >= 2:\n",
    "    top2 = leader_df.head(2)[\"model\"].tolist()\n",
    "    print(f\"\\n[INFO] 상위 2개 모델 앙상블: {top2}\")\n",
    "    oof_true = oof_preds_by_model[top2[0]][0]\n",
    "    pred1 = oof_preds_by_model[top2[0]][1]\n",
    "    pred2 = oof_preds_by_model[top2[1]][1]\n",
    "\n",
    "    rmse1 = leader_df.iloc[0][\"RMSE\"]\n",
    "    rmse2 = leader_df.iloc[1][\"RMSE\"]\n",
    "    w1, w2 = 1/rmse1, 1/rmse2\n",
    "    ens_pred = (w1*pred1 + w2*pred2)/(w1+w2)\n",
    "\n",
    "    mse = mean_squared_error(oof_true, ens_pred)\n",
    "    rmse, r2 = math.sqrt(mse), r2_score(oof_true, ens_pred)\n",
    "    print(f\"[앙상블] RMSE={rmse:.4f}, R²={r2:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(oof_true, ens_pred, s=8, alpha=0.6)\n",
    "    lims_min, lims_max = min(oof_true.min(), ens_pred.min()), max(oof_true.max(), ens_pred.max())\n",
    "    plt.plot([lims_min, lims_max],[lims_min, lims_max])\n",
    "    X_mat = np.c_[np.ones_like(oof_true), oof_true]\n",
    "    beta, *_ = np.linalg.lstsq(X_mat, ens_pred, rcond=None)\n",
    "    line_x = np.linspace(lims_min, lims_max, 100)\n",
    "    plt.plot(line_x, beta[0]+beta[1]*line_x)\n",
    "    plt.xlabel(\"실측값\"); plt.ylabel(\"예측값\")\n",
    "    plt.title(f\"앙상블({'+'.join(top2)}) 회귀선\\nRMSE={rmse:.3f}, R²={r2:.3f}\")\n",
    "    plt.tight_layout(); plt.savefig(\"figs/scatter_regline_Ensemble.png\", dpi=200); plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
