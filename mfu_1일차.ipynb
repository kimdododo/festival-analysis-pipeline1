{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPBEJf5ZhLgcLqeUH5Ofb7E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimdododo/festival-analysis-pipeline1/blob/main/mfu_1%EC%9D%BC%EC%B0%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY1MlNH_phZA",
        "outputId": "bccdc0a9-f910-4a80-bb2c-c2fa7a8c1715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "PyTorch: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "import sys, torch, platform\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"PyTorch:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install calflops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xUeCch7rAMa",
        "outputId": "9ba48c1e-4f64-4a9a-8803-0baafa884422"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting calflops\n",
            "  Downloading calflops-0.3.2-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: accelerate>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from calflops) (1.10.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from calflops) (0.35.3)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from calflops) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.22.0->calflops) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.22.0->calflops) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.22.0->calflops) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.22.0->calflops) (6.0.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.22.0->calflops) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.16.4->calflops) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.16.4->calflops) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.16.4->calflops) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.16.4->calflops) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.16.4->calflops) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.16.4->calflops) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->calflops) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.1.0->calflops) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.1.0->calflops) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.16.4->calflops) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.16.4->calflops) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.16.4->calflops) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.16.4->calflops) (2025.10.5)\n",
            "Downloading calflops-0.3.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: calflops\n",
            "Successfully installed calflops-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from calflops import calculate_flops\n",
        "\n",
        "def parse_flop_string(s):\n",
        "    return float(s.strip().split()[0])\n",
        "\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', weights='ResNet18_Weights.DEFAULT')\n",
        "\n",
        "flops, macs, params = calculate_flops(\n",
        "    model=model,\n",
        "    input_shape=(1, 3, 224, 224),\n",
        "    print_results=False\n",
        ")\n",
        "\n",
        "print(f\"FLOPs: {parse_flop_string(flops):.2f}G, MACs: {parse_flop_string(macs):.2f}G\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l1ICr4grGrw",
        "outputId": "97e5901f-f647-47d0-8fc8-be9cdc7ffb3a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 191MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLOPs: 3.64G, MACs: 1.81G\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, time, os\n",
        "\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "    os.system(\"nvidia-smi | head -n 20\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WlSnrDrsv3N",
        "outputId": "08a8459d-026f-44df-e95d-9003cf49424c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3, 32, 3, stride=2, padding=1)\n",
        "        self.fc = nn.Linear(32 * 112 * 112, 10)\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "model = SimpleCNN().cuda().eval()"
      ],
      "metadata": {
        "id": "xzIFMquFsv5l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FLOPs = 2 * H * W * Cin * Cout * Kh * Kw\n",
        "H, W, Cin, Cout, Kh, Kw = 224, 224, 3, 32, 3, 3\n",
        "flops_conv = 2 * H/2 * W/2 * Cin * Cout * Kh * Kw  # stride=2 â†’ H/2,W/2\n",
        "flops_fc = 2 * (32 * 112 * 112) * 10\n",
        "total_flops = flops_conv + flops_fc\n",
        "print(f\"ì´ FLOPs: {total_flops/1e9:.3f} GFLOPs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xed1IByxsv7k",
        "outputId": "e9ffbdfe-06d2-44f6-b104-49a3e40197d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì´ FLOPs: 0.030 GFLOPs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(32, 3, 224, 224).cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "y = torch.randint(0, 10, (32,)).cuda()\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "start = time.time()\n",
        "\n",
        "for _ in range(50):  # 50 iterations\n",
        "    optimizer.zero_grad()\n",
        "    out = model(x)\n",
        "    loss = criterion(out, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "end = time.time()\n",
        "train_time = (end - start) / 50\n",
        "print(f\"í‰ê·  ë°˜ë³µë‹¹ í•™ìŠµ ì‹œê°„: {train_time:.4f} ì´ˆ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcgI2drJsv9s",
        "outputId": "7640c761-e2a3-4d2b-99f9-f274bda75ecb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "í‰ê·  ë°˜ë³µë‹¹ í•™ìŠµ ì‹œê°„: 0.0221 ì´ˆ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_theoretical_flops = 19.5e12  # A100 ê¸°ì¤€ (FP32)\n",
        "mfu = (total_flops / train_time) / gpu_theoretical_flops * 100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f\"ðŸ”¹ MFU(Model FLOPs Utilization): {mfu:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzGJUDDNsv_0",
        "outputId": "7043015c-b870-4891-f7ec-3390ebf51657"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¹ MFU(Model FLOPs Utilization): 0.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --query-gpu=utilization.gpu,utilization.memory,memory.used --format=csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9ABptxPswB9",
        "outputId": "382b0ce7-462d-4ca7-e0f0-a65563467d2a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "utilization.gpu [%], utilization.memory [%], memory.used [MiB]\n",
            "21 %, 14 %, 809 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# FC (Linear) ë ˆì´ì–´ ì •ì˜\n",
        "N_in, N_out = 4, 3\n",
        "fc = nn.Linear(N_in, N_out, bias=False)\n",
        "\n",
        "# ìž…ë ¥ ë°ì´í„° (ë°°ì¹˜ í¬ê¸° 1)\n",
        "x = torch.randn(1, N_in)\n",
        "y = fc(x)\n",
        "\n",
        "print(\"ìž…ë ¥ í¬ê¸°:\", x.shape)\n",
        "print(\"ì¶œë ¥ í¬ê¸°:\", y.shape)\n",
        "\n",
        "# FLOPs ê³„ì‚°\n",
        "flops = 2 * N_in * N_out\n",
        "print(f\"ì´ë¡ ì  FLOPs: {flops} íšŒ ì—°ì‚° (ê³±ì…ˆ + ë§ì…ˆ í¬í•¨)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-F-_QGTs9p0",
        "outputId": "67fd6dee-a870-43d5-eb63-54ad2050fc23"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ìž…ë ¥ í¬ê¸°: torch.Size([1, 4])\n",
            "ì¶œë ¥ í¬ê¸°: torch.Size([1, 3])\n",
            "ì´ë¡ ì  FLOPs: 24 íšŒ ì—°ì‚° (ê³±ì…ˆ + ë§ì…ˆ í¬í•¨)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# ìž…ë ¥ ë° ì»¤ë„ ì •ì˜\n",
        "x = torch.randn(1, 3, 4, 4)   # (ë°°ì¹˜, ì±„ë„, ë†’ì´, ë„ˆë¹„)\n",
        "conv = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=3, stride=1, padding=0)\n",
        "\n",
        "# ì—°ì‚° ìˆ˜í–‰\n",
        "y = conv(x)\n",
        "print(\"ì¶œë ¥ í¬ê¸°:\", y.shape)\n",
        "\n",
        "# FLOPs ê³„ì‚° ê³µì‹ ì ìš©\n",
        "H_out, W_out = y.shape[2], y.shape[3]\n",
        "K_h, K_w = conv.kernel_size\n",
        "C_in, C_out = conv.in_channels, conv.out_channels\n",
        "\n",
        "flops = 2 * H_out * W_out * K_h * K_w * C_in * C_out\n",
        "print(f\"ì´ë¡ ì  FLOPs: {flops} íšŒ ì—°ì‚°\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29XEoLsaxZj_",
        "outputId": "f8d4ac53-6201-4074-cb24-329dd6d109aa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì¶œë ¥ í¬ê¸°: torch.Size([1, 1, 2, 2])\n",
            "ì´ë¡ ì  FLOPs: 216 íšŒ ì—°ì‚°\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# ê°„ë‹¨í•œ ëª¨ë¸ ì •ì˜\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3, 16, 3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 32, 3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(32 * 32 * 32, 10)\n",
        ")\n",
        "\n",
        "x = torch.randn(1, 3, 32, 32)\n",
        "\n",
        "# MACs ê³„ì‚° ì˜ˆì‹œ\n",
        "H_out, W_out = 32, 32\n",
        "K_h, K_w = 3, 3\n",
        "C_in, C_out = 3, 16\n",
        "\n",
        "conv1_macs = H_out * W_out * K_h * K_w * C_in * C_out\n",
        "print(f\"Conv1 MACs: {conv1_macs / 1e6:.2f} MMACs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbhEOlCAxb-R",
        "outputId": "db208fdb-aeb7-49a6-ec45-e26c7fd1407f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv1 MACs: 0.44 MMACs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.profiler as profiler"
      ],
      "metadata": {
        "id": "CwdEie0Wxroo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.Linear(1024, 1024).cuda()\n",
        "input_data = torch.randn(16, 1024).cuda()"
      ],
      "metadata": {
        "id": "2OvFWTSIxyDg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "J9_kMTayMYh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [2] í”„ë¡œíŒŒì¼ë§ìš© ê¸°ë³¸ ì„¤ì •ê°’\n",
        "batch_size = 16\n",
        "iterations = 50   # ì´ ë°˜ë³µ íšŸìˆ˜"
      ],
      "metadata": {
        "id": "VUCjyyx6xyGR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# [3] torch.profilerë¡œ CPU/GPU ì‹œê°„ ì¸¡ì •\n",
        "with profiler.profile(\n",
        "    activities=[profiler.ProfilerActivity.CPU, profiler.ProfilerActivity.CUDA],\n",
        "    record_shapes=True\n",
        ") as prof:\n",
        "    for i in range(iterations):\n",
        "        output = model(input_data)\n",
        "        loss = output.sum()\n",
        "        loss.backward()\n",
        "        torch.cuda.synchronize()   # GPU ì—°ì‚° ì™„ë£Œ ëŒ€ê¸° (ì •í™•í•œ ì‹œê°„ ì¸¡ì •ìš©)"
      ],
      "metadata": {
        "id": "riisEWzAxyIm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# [4] í”„ë¡œíŒŒì¼ë§ ê²°ê³¼ì—ì„œ í‰ê·  ìˆ˜í–‰ì‹œê°„ ê³„ì‚°\n",
        "events = prof.key_averages()   # ê°œë³„ ì—°ì‚°ë³„ ì§‘ê³„\n",
        "total_cpu_time = sum([e.self_cpu_time_total for e in events]) / 1e6  # (ms â†’ s)\n",
        "time_per_iter = total_cpu_time / iterations\n",
        "print(f\"ðŸ•’ ë°˜ë³µ 1íšŒë‹¹ í‰ê·  ìˆ˜í–‰ì‹œê°„: {time_per_iter:.6f} ì´ˆ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsK5fWmVxyLL",
        "outputId": "73403fcb-6833-43a0-f52b-3ccf97396563"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ•’ ë°˜ë³µ 1íšŒë‹¹ í‰ê·  ìˆ˜í–‰ì‹œê°„: 0.001547 ì´ˆ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [5] ì²˜ë¦¬ëŸ‰(Throughput) ê³„ì‚°\n",
        "throughput = batch_size / time_per_iter\n",
        "print(f\"ì²˜ë¦¬ëŸ‰(Throughput): {throughput:.2f} ìƒ˜í”Œ/ì´ˆ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iywdC8lhxyNh",
        "outputId": "660a29fb-9f6c-4585-c750-d449e2f4991b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì²˜ë¦¬ëŸ‰(Throughput): 10343.19 ìƒ˜í”Œ/ì´ˆ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flops_per_sample = 1e9  # ì˜ˆì‹œ: 1 GFLOP / ìƒ˜í”Œ\n",
        "total_flops = flops_per_sample * batch_size"
      ],
      "metadata": {
        "id": "XayRuHq6yjtf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_peak_flops = 19.5 * 1e12  # FP32 ê¸°ì¤€"
      ],
      "metadata": {
        "id": "M8ZCbkYRxyPu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfu = (total_flops / time_per_iter) / gpu_peak_flops\n",
        "print(f\"ðŸ”¥ MFU (Model FLOPs Utilization): {mfu:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nK_fS8LxyUj",
        "outputId": "e683daf1-18f1-487b-f974-1198195dd264"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¥ MFU (Model FLOPs Utilization): 53.04%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device('cuda')\n",
        "torch.backends.cudnn.benchmark = True  # conv ê°€ì†\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3, 32, 3, stride=2, padding=1)\n",
        "        self.fc = nn.Linear(32 * 112 * 112, 10)\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "model = SimpleCNN().to(device).train()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# ---- FLOPs per-sample (forward) ----\n",
        "H, W, Cin, Cout, Kh, Kw = 224, 224, 3, 32, 3, 3\n",
        "Hout, Wout = H//2, W//2  # stride=2\n",
        "flops_conv_fwd = 2 * Hout * Wout * Cin * Cout * Kh * Kw\n",
        "flops_fc_fwd   = 2 * (32 * 112 * 112) * 10\n",
        "fwd_flops_per_sample = flops_conv_fwd + flops_fc_fwd\n",
        "\n",
        "batch_size = 32\n",
        "x = torch.randn(batch_size, 3, 224, 224, device=device)\n",
        "y = torch.randint(0, 10, (batch_size,), device=device)\n",
        "\n",
        "# ---- warmup ----\n",
        "for _ in range(10):\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss = criterion(model(x), y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "# ---- timing ----\n",
        "iters = 50\n",
        "t0 = time.time()\n",
        "for _ in range(iters):\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    out = model(x)\n",
        "    loss = criterion(out, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "torch.cuda.synchronize()\n",
        "t1 = time.time()\n",
        "\n",
        "iter_time = (t1 - t0) / iters\n",
        "\n",
        "# ---- FLOPs per-iter (train) â‰ˆ 3x forward ----\n",
        "iter_flops = batch_size * fwd_flops_per_sample * 3\n",
        "\n",
        "# ---- GPU peak FLOPs: ì •ë°€ë„ì— ë§žì¶° ì„¤ì • ----\n",
        "# FP32 ì˜ˆì‹œ: A100 â‰ˆ 19.5e12 FLOPs/s\n",
        "gpu_peak_flops = 19.5e12\n",
        "\n",
        "mfu = (iter_flops / iter_time) / gpu_peak_flops * 100.0\n",
        "print(f\"í‰ê·  ë°˜ë³µë‹¹ ì‹œê°„: {iter_time:.4f}s\")\n",
        "print(f\"MFU â‰ˆ {mfu:.2f}%  (FP32 ê¸°ì¤€)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oG-7A0l1MzHR",
        "outputId": "877ed1c1-9059-4645-cd54-c3499a16e7b4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "í‰ê·  ë°˜ë³µë‹¹ ì‹œê°„: 0.0013s\n",
            "MFU â‰ˆ 11.04%  (FP32 ê¸°ì¤€)\n"
          ]
        }
      ]
    }
  ]
}